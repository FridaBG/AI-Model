# Clasificador de Im√°genes

&nbsp;

## üñºÔ∏è Generaci√≥n del set de datos

### 1. Obtener set de datos

El conjunto de datos utilizado fue tomado de Kaggle: üîó [_Sports Balls ‚Äì Multiclass Image Classification_](https://www.kaggle.com/datasets/samuelcortinhas/sports-balls-multiclass-image-classification/data)

Aunque el dataset original incluye una variedad m√°s amplia de clases, se seleccionaron √∫nicamente **4 categor√≠as** con el objetivo de reducir el tiempo de entrenamiento, se seleccionaron las siguientes clases:

- üèà Football
- üèè Cricket
- ‚öΩ Soccer
- üéæ Tenis

Se agregaron im√°genes extra a todas las clases para asegurar un buen balance y tener un mejor rendimiento al aumentar el dataset.

> **¬øEst√° balanceado?** S√≠, hay la misma cantidad de im√°genes por clase (840 cada una)

> **¬øEs correcto?** S√≠, las im√°genes est√°n correctamente etiquetadas y clasificadas.

> **¬øEs representativo?** S√≠, incluye variedad suficiente de im√°genes para cada clase.

### 2. Divisi√≥n del det de datos

  <img src="https://velog.velcdn.com/images/iguv/post/8ae842e3-f2b6-44c5-b7bf-a1f74b3a9124/image.png" width="300"/>
  
  Para entrenar un modelo que realmente aprenda a clasificar y no solo memorice, es importante dividir el dataset en tres partes:

- **Training**
  - _700 im√°genes por clase (80%)_
  - Aqu√≠ es donde el modelo ‚Äúaprende‚Äù haciendo los ajustes internos necesarios para reducir el error.
  - Entrena directamente el modelo
- **Validation**
  - _70 im√°genes por clase (10%)_
  - Se usa mientras el modelo entrena, pero no se le muestra nunca para aprender.
    Ayuda a medir si el modelo est√° empezando a "overfit" y permite ajustar o detener el entrenamiento en el mejor momento.
  - Sirve para monitorear el rendimiento sin hacer trampa.
- **Testing**
  - _70 im√°genes por clase (10%)_
  - Se guarda hasta el final. Es un grupo de datos nunca visto por el modelo ni durante el entrenamiento ni durante la validaci√≥n.
  - Sirve para saber qu√© tan bien clasifica el modelo a datos nuevos.

## ‚öôÔ∏è Preprocesado de los datos

### 1. T√©cnicas de escalamiento

- `rescale=1./255`: Convierte los valores de p√≠xeles de [0, 255] a [0, 1]
- Acelera el entrenamiento
- Mejora la estabilidad del modelo

### 2. Preprocesado de los datos

T√©cnicas de preprocesamiento de datos para mejorar la categorizaci√≥n del modelo:

- `rotation_range=30`: gira aleatoriamente la imagen
- `width_shift_range=0.1`: desplaza horizontalmente
- `height_shift_range=0.1`: desplaza verticalmente
- `shear_range=0.2`: aplica corte en la im√°gen
- `zoom_range=0.4`: hace zoom aleatorio
- `brightness_range=[0.8, 1.1]`: cambia el brillo
- `fill_mode='nearest'`: rellena los huecos generados por estas transformaciones

  <img src="https://i.postimg.cc/022CjTWN/Captura-de-pantalla-2025-05-24-a-la-s-7-00-36-p-m.png" width="800"/>

  üîó [Documentaci√≥n Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)

## üöß Implementaci√≥n del modelo

### 1. Seleccionar un modelo

Para esta implementaci√≥n me bas√© en el modelo ICNN-BNDOA propuesto en el art√≠culo **"Improved CNN Based on Batch Normalization and Adam"** publicado en Advances in Intelligent Systems and Computing (Springer). Esta arquitectura se dise√±√≥ espec√≠ficamente para mejorar el rendimiento de las CNN en tareas de clasificaci√≥n mediante la combinaci√≥n de tres t√©cnicas principales:

- Batch Normalization (BN) para estabilizar y acelerar el entrenamiento.

- Dropout (DO) como t√©cnica para mitigar el overfitting.

- Optimizaci√≥n con Adam, dada su eficiencia y adaptabilidad.

> ‚ÄúThis research created a seven-layer CNN model that includes an input layer with BN and DO layers, two hidden layers with BN and DO layers composed of convolution and pool layers, a flatten layer with DO layer (0.3), a fully connected layer, two dense layers with BN and DO layers, and an output layer with sigmoid activation.‚Äù

Esta propuesta utiliza una red con m√∫ltiples capas convolucionales intercaladas con BN y DO, seguida de capas densas totalmente conectadas con activaci√≥n ReLU y salida sigmoid para tareas binarias (en mi caso, adaptada a softmax para clasificaci√≥n multiclase).

### 2. Implementar el modelo seleccionado

Inspirado en la estructura general del modelo ICNN-BNDOA, implement√© una red CNN adaptada a mi conjunto de datos. Dado el tama√±o relativamente peque√±o del dataset, decid√≠ no incluir Batch Normalization, por las siguiente raz√≥n:

- **Peor rendimiento observado emp√≠ricamente:** al implementar BN despu√©s de cada capa convolucional (como lo sugiere el art√≠culo), not√© un descenso en la precisi√≥n tanto en el conjunto de validaci√≥n como de prueba. Esto podr√≠a deberse a que BN introduce una estimaci√≥n de media y varianza por batch, lo cual puede no generalizar bien en datasets peque√±os, como indican varios estudios:

> "Batch normalization works best with large datasets and batch sizes, and its effectiveness can be limited when data is scarce or imbalanced." (Goodfellow et al., Deep Learning, 2016)

- En su lugar, utilic√© una tasa de Dropout del 30%, lo cual proporcion√≥ un mejor control del overfitting

La arquitectura final incluye:

- 3 bloques Conv2D + MaxPooling2D, con activaci√≥n ReLU.
- Dropout(0.3) aplicado despu√©s de las dos √∫ltimas capas convolucionales.
- 1 capa Flatten para vectorizar.
- Dropout(0.3) adicional antes de la capa densa final.
- 1 capa Dense(64) con activaci√≥n ReLU.
- 1 capa Dense final con activaci√≥n softmax para clasificaci√≥n en 4 clases.
- Entrenamiento con el optimizador Adam, con una tasa de aprendizaje de 1e-4.

Esta configuraci√≥n fue seleccionada tras pruebas comparativas, logrando mejorar la precisi√≥n del modelo y reducir el riesgo de overfitting, sin necesidad de aumentar la complejidad de la arquitectura.

## üìà Evaluaci√≥n inicial del modelo

### 1. Seleccionar m√©tricas adecuadas

Para evaluar el desempe√±o de mi modelo de clasificaci√≥n multiclase, seleccion√© la m√©trica **accuracy**. Esta elecci√≥n est√° respaldada por el art√≠culo **"A comprehensive survey of loss functions and metrics in deep learning"** , donde se destaca que:

> ‚ÄúAccuracy remains the most widely used metric for classification tasks, especially when the dataset is balanced and the misclassification costs are uniform across classes.‚Äù

Dado que mi conjunto de datos est√° equilibrado entre las cuatro clases y no existen penalizaciones diferenciadas por errores de clasificaci√≥n, la m√©trica accuracy proporciona una evaluaci√≥n clara y directa del rendimiento general del modelo.

En cuanto a la funci√≥n de p√©rdida, utilic√© **categorical_crossentropy**, que es la opci√≥n est√°ndar para problemas de clasificaci√≥n multiclase. Esta elecci√≥n tambi√©n est√° respaldada por el art√≠culo mencionado anteriormente, que indica:

> ‚ÄúCategorical cross-entropy is the default loss function for multi-class classification tasks, offering a probabilistic interpretation and aligning well with the softmax activation in the output layer.‚Äù

Esta funci√≥n de p√©rdida mide la divergencia entre las distribuciones de probabilidad predichas y las verdaderas, lo que la hace especialmente adecuada para modelos con una capa de salida softmax, como es el caso de mi implementaci√≥n.

### 2. Reporte de resultados obtenidos e interpretaci√≥n.

El modelo alcanz√≥ un accuracy final en el conjunto de prueba de 0.789 (78.9%), como se muestra tanto en la m√©trica global como en las gr√°ficas de desempe√±o. La curva de accuracy muestra una mejora constante en el entrenamiento, y aunque el data de validation es m√°s inestable, ambas curvas est√°n en valores altos, lo que indica que el modelo logra aprender sin caer en un overfitting grave.

En contraste, la curva de loss se comporta de forma distinta. Esto es normal, ya que la funci√≥n de p√©rdida (categorical_crossentropy) no siempre se realciona directamente con el accuracy, especialmente en clasificaci√≥n multiclase. Adem√°s la **val loss** fluct√∫a porque el conjunto de validaci√≥n es peque√±o, y basta que falle una clase para subir el valor de loss.

<img src="https://i.postimg.cc/Lsw1ngb9/Captura-de-pantalla-2025-05-25-a-la-s-5-43-05-p-m.png" width="400"/>
<img src="https://i.postimg.cc/nrYjRRcr/Captura-de-pantalla-2025-05-25-a-la-s-5-43-42-p-m.png" width="400"/>

La **matriz de confusi√≥n** muestra que el modelo logra un buen desempe√±o general, con las cuatro clases bien representadas. Tennis fue la clase mejor clasificada, con 62 de 70 ejemplos correctamente identificados. Football tambi√©n mostr√≥ alta precisi√≥n, con 56 aciertos. Sin embargo, se observa que cricket fue confundida con soccer y tennis en 10 casos cada una, lo que indica similitudes visuales entre estas clases. Por otro lado, soccer present√≥ errores distribuidos entre las dem√°s clases. Aun as√≠, el modelo mantiene un buen equilibrio de clasificaci√≥n entre todas las clases.

<img src="https://i.postimg.cc/65tG2XYv/Captura-de-pantalla-2025-05-25-a-la-s-5-44-26-p-m.png" width="400"/>

---

Ogundokun, R.O., Maskeliunas, R., Misra, S., Dama≈°eviƒçius, R. (2022). Improved CNN Based on Batch Normalization and Adam Optimizer. In: Gervasi, O., Murgante, B., Misra, S., Rocha, A.M.A.C., Garau, C. (eds) Computational Science and Its Applications ‚Äì ICCSA 2022 Workshops. ICCSA 2022. Lecture Notes in Computer Science, vol 13381. Springer, Cham. https://doi.org/10.1007/978-3-031-10548-7_43

Terven, J., Cordova-Esparza, DM., Romero-Gonz√°lez, JA. et al. A comprehensive survey of loss functions and metrics in deep learning. Artif Intell Rev 58, 195 (2025). https://doi.org/10.1007/s10462-025-11198-7
